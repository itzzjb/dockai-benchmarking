name: Compare DockAI vs Human vs CNB (Academic Benchmark)

on:
  workflow_dispatch:
  push:
    branches: [main]
    paths:
      - config.json

jobs:
  compare:
    name: Empirical Evaluation (Size, Time, Security)
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      TARGET_DIR: target-repo
      REPORT_PATH: report.md
      HUMAN_IMG: human:compare
      DOCKAI_IMG: dockai:compare
      CNB_IMG: cnb:compare
      PACK_VERSION: 0.36.2

    steps:
      - name: Checkout workflow repo
        uses: actions/checkout@v6.0.1

      - name: Install dependencies
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y jq bc

      - name: Set up Trivy CLI (0.68.1)
        uses: aquasecurity/setup-trivy@e6c2c5e321ed9123bda567646e2f96565e34abe1
        with:
          version: v0.68.1
          cache: true

      - name: Set up pack CLI
        uses: buildpacks/github-actions/setup-pack@v5.9.7
        with:
          pack-version: ${{ env.PACK_VERSION }}

      - name: Resolve repository and branch
        id: repo
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          input_repo="${{ github.event.inputs.repo_url }}"
          input_branch="${{ github.event.inputs.branch }}"

          # Fallback to config.json if input is empty
          # (Ensure config.json exists or ignore errors if it doesn't)
          if [ -f config.json ]; then
            config_repo=$(jq -r '.repository_url // empty' config.json)
          else
            config_repo=""
          fi

          raw_repo="${input_repo:-$config_repo}"

          if [ -z "$raw_repo" ]; then echo "Repo URL required" >&2; exit 1; fi

          # --- FIX: SMART URL DETECTION ---
          if [[ "$raw_repo" =~ ^https?:// ]]; then
            clone_url="$raw_repo"
          else
            clone_url="https://github.com/${raw_repo}"
          fi

          # --- FIX: ROBUST AUTH INSERTION ---
          auth_clone_url="$clone_url"
          if [ -n "${GITHUB_TOKEN:-}" ]; then
             # Strip existing protocol (http:// or https://) to insert credentials
             clean_url="${clone_url#*://}"
             auth_clone_url="https://${GITHUB_ACTOR:-github-actions}:${GITHUB_TOKEN}@${clean_url}"
          fi

          echo "clone_url=$clone_url" >> "$GITHUB_OUTPUT"
          echo "auth_clone_url=$auth_clone_url" >> "$GITHUB_OUTPUT"
          echo "repo_label=$raw_repo" >> "$GITHUB_OUTPUT"
          echo "branch=${input_branch:-main}" >> "$GITHUB_OUTPUT"

      - name: Checkout target repo
        run: |
          set -euo pipefail
          rm -rf "${TARGET_DIR}"
          git clone --depth 1 "${{ steps.repo.outputs.auth_clone_url }}" "${TARGET_DIR}"
          # Reset remote to avoid token leak
          git -C "${TARGET_DIR}" remote set-url origin "${{ steps.repo.outputs.clone_url }}"

      - name: Backup human Dockerfile
        run: |
          if [ -f "${TARGET_DIR}/Dockerfile" ]; then
            cp "${TARGET_DIR}/Dockerfile" "${TARGET_DIR}/Dockerfile.human.bak"
          fi

      - name: Set up Docker Buildx (for DockAI)
        uses: docker/setup-buildx-action@v3.11.1

      - name: Verify Docker daemon and warm images
        run: |
          set -euo pipefail
          sudo systemctl start docker || true
          docker info
          docker version
          # Pre-pull likely bases so DockAI doesn't fail on network hiccups
          docker pull node:18.16.0-alpine || true
          docker pull nginx:1.20 || true

      - name: Generate DockAI Dockerfile
        uses: itzzjb/dockai@v3
        continue-on-error: true
        with:
          openai_api_key: ${{ secrets.OPENAI_API_KEY }}
          project_path: ${{ env.TARGET_DIR }}
          max_retries: 5
          langchain_tracing_v2: true
          langchain_api_key: ${{ secrets.LANGCHAIN_API_KEY }}
          langchain_project: dockai

      - name: Organize Dockerfiles
        run: |
          # Save DockAI file
          if [ -f "${TARGET_DIR}/Dockerfile" ]; then
            mv "${TARGET_DIR}/Dockerfile" "${TARGET_DIR}/Dockerfile.dockai"
          fi
          # Restore Human file
          if [ -f "${TARGET_DIR}/Dockerfile.human.bak" ]; then
            mv "${TARGET_DIR}/Dockerfile.human.bak" "${TARGET_DIR}/Dockerfile"
          fi

      - name: Purge study images (keep action images)
        if: always()
        run: |
          set -euo pipefail
          # Remove only the study images to avoid deleting GitHub Action images
          docker image rm -f "${HUMAN_IMG}" "${DOCKAI_IMG}" "${CNB_IMG}" 2>/dev/null || true
          # Optional: clean BuildKit cache without touching pulled action images
          docker builder prune -af || true

      - name: Check Artifact Existence
        id: detect
        run: |
          [ -f "${TARGET_DIR}/Dockerfile" ] && echo "human_present=true" >> "$GITHUB_OUTPUT" || echo "human_present=false" >> "$GITHUB_OUTPUT"
          [ -f "${TARGET_DIR}/Dockerfile.dockai" ] && echo "dockai_present=true" >> "$GITHUB_OUTPUT" || echo "dockai_present=false" >> "$GITHUB_OUTPUT"

      - name: Hadolint Human Dockerfile
        if: steps.detect.outputs.human_present == 'true'
        uses: hadolint/hadolint-action@v3.1.0
        with:
          dockerfile: ${{ env.TARGET_DIR }}/Dockerfile
          format: json
          output-file: hadolint-human.json

      - name: Hadolint DockAI Dockerfile
        if: steps.detect.outputs.dockai_present == 'true'
        uses: hadolint/hadolint-action@v3.1.0
        with:
          dockerfile: ${{ env.TARGET_DIR }}/Dockerfile.dockai
          format: json
          output-file: hadolint-dockai.json

      - name: Stub Hadolint for CNB (no Dockerfile)
        run: echo "[]" > hadolint-cnb.json

      # --- BUILD & TIME MEASUREMENT STEPS ---

      - name: Build Human (Measure Time)
        if: steps.detect.outputs.human_present == 'true'
        run: |
          # Continue even if the build fails so later steps can still run
          set -u -o pipefail
          start=$(date +%s)
          if docker build --no-cache --file "${TARGET_DIR}/Dockerfile" --tag "${HUMAN_IMG}" "${TARGET_DIR}"; then
            status="success"
          else
            status="failed"
          fi
          end=$(date +%s)
          echo "$((end-start))" > human_time.txt
          echo "$status" > human_status.txt

      - name: Build DockAI (Measure Time)
        if: steps.detect.outputs.dockai_present == 'true'
        run: |
          set -u -o pipefail
          start=$(date +%s)
          if docker build --no-cache --file "${TARGET_DIR}/Dockerfile.dockai" --tag "${DOCKAI_IMG}" "${TARGET_DIR}"; then
            status="success"
          else
            status="failed"
          fi
          end=$(date +%s)
          echo "$((end-start))" > dockai_time.txt
          echo "$status" > dockai_status.txt

      - name: Build CNB (Measure Time)
        run: |
          set -u -o pipefail
          start=$(date +%s)
          if pack build "${CNB_IMG}" --builder paketobuildpacks/builder:base --path "${TARGET_DIR}" --pull-policy if-not-present --clear-cache; then
            status="success"
          else
            status="failed"
          fi
          end=$(date +%s)
          echo "$((end-start))" > cnb_time.txt
          echo "$status" > cnb_status.txt

      # --- METRIC COLLECTION ---

      - name: Trivy Scans
        if: always()
        run: |
          # Function to run trivy safely
          run_trivy() {
            local img=$1
            local out=$2
            if docker image inspect "$img" >/dev/null 2>&1; then
              trivy image --format json --output "$out" --severity CRITICAL,HIGH,MEDIUM,LOW "$img"
            else
              echo "{}" > "$out"
            fi
          }
          run_trivy "${HUMAN_IMG}" trivy-human.json
          run_trivy "${DOCKAI_IMG}" trivy-dockai.json
          run_trivy "${CNB_IMG}" trivy-cnb.json

      - name: Calculate Academic Metrics (C_total)
        if: always()
        id: math
        env:
          W_SIZE: 0.3
          W_TIME: 0.2
          W_SEC: 0.5
        run: |
          set -e

          # 1. ROBUST METRIC EXTRACTION
          get_status() { [ -f "$1" ] && cat "$1" || echo "missing"; }
          get_size() { docker image inspect "$1" --format '{{.Size}}' 2>/dev/null || echo 0; }
          get_time() { cat "$1" 2>/dev/null || echo 0; }

          # Security Index Calculation (Fixed for null .Results)
          get_omega() {
            local f=$1
            # Check if file exists and has content
            if [ ! -s "$f" ]; then echo 0; return; fi
            
            # Run jq with error handling (|| echo 0)
            # Added '?' after .Results[] to prevent crash if Results is null
            jq -r '
              reduce (.Results[]?.Vulnerabilities[]? // empty) as $v (0; 
                if $v.Severity == "CRITICAL" then . + 10
                elif $v.Severity == "HIGH" then . + 5
                elif $v.Severity == "MEDIUM" then . + 2
                elif $v.Severity == "LOW" then . + 1
                else . end
              )
            ' "$f" || echo 0
          }

          # Hadolint error/warning counters (safe on missing/empty files)
          get_lint_counts() {
            local f="$1"
            if [ ! -s "$f" ]; then echo "0 0"; return; fi
            jq -r '
              reduce .[]? as $i ([0,0];
                if ($i.level == "error") then [.[0]+1, .[1]]
                elif ($i.level == "warning" or $i.level == "info") then [.[0], .[1]+1]
                else . end
              ) | @tsv
            ' "$f" 2>/dev/null || echo "0 0"
          }

          calc_penalty() {
            local errs="${1:-0}"
            local warns="${2:-0}"
            awk -v e="$errs" -v w="$warns" 'BEGIN {printf "%.4f", (e*0.1) + (w*0.05)}'
          }

          calc_final() {
            local base="${1:-0}"
            local pen="${2:-0}"
            awk -v b="$base" -v p="$pen" 'BEGIN {printf "%.4f", b + p}'
          }

          # Get Raw Values
          h_status=$(get_status human_status.txt); d_status=$(get_status dockai_status.txt); c_status=$(get_status cnb_status.txt)
          h_size=$(get_size "${HUMAN_IMG}"); h_time=$(get_time human_time.txt); h_omega=$(get_omega trivy-human.json)
          d_size=$(get_size "${DOCKAI_IMG}"); d_time=$(get_time dockai_time.txt); d_omega=$(get_omega trivy-dockai.json)
          c_size=$(get_size "${CNB_IMG}");    c_time=$(get_time cnb_time.txt);   c_omega=$(get_omega trivy-cnb.json)

          # Lint counts (tolerate empty output from jq)
          if ! read h_err h_warn <<< "$(get_lint_counts hadolint-human.json)"; then h_err=0; h_warn=0; fi
          if ! read d_err d_warn <<< "$(get_lint_counts hadolint-dockai.json)"; then d_err=0; d_warn=0; fi
          if ! read c_err c_warn <<< "$(get_lint_counts hadolint-cnb.json)"; then c_err=0; c_warn=0; fi

          # Coerce missing or non-positive values to safe defaults to avoid awk/bc errors
          default_zero() { local v="$1"; [ -z "$v" ] && echo 0 || echo "$v"; }
          default_one() {
            local v="$1"
            if [ -z "$v" ]; then echo 1; elif [ "$v" -le 0 ] 2>/dev/null; then echo 1; else echo "$v"; fi
          }

          h_size=$(default_zero "$h_size"); h_time=$(default_zero "$h_time"); h_omega=$(default_zero "$h_omega")
          d_size=$(default_zero "$d_size"); d_time=$(default_zero "$d_time"); d_omega=$(default_zero "$d_omega")
          c_size=$(default_one "$c_size");  c_time=$(default_one "$c_time");  c_omega=$(default_one "$c_omega")

          h_err=$(default_zero "$h_err"); h_warn=$(default_zero "$h_warn")
          d_err=$(default_zero "$d_err"); d_warn=$(default_zero "$d_warn")
          c_err=$(default_zero "$c_err"); c_warn=$(default_zero "$c_warn")

          # 2. ZERO-DIVISION PROTECTION (For Baseline)
          # If any baseline metric is 0, set it to 1 to allow division
          [ "$c_size" -le 0 ] && c_size=1
          [ "$c_time" -le 0 ] && c_time=1
          [ "$c_omega" -le 0 ] && c_omega=1

          echo "DEBUG: Baseline - Size:$c_size Time:$c_time Omega:$c_omega"

          # 3. CALCULATE METRICS (Awk)
          calc_metrics() {
             # Ensure inputs are not empty strings, default to 0
             local s="${1:-0}"
             local t="${2:-0}"
             local w="${3:-0}"
             
             awk -v s="$s" -v t="$t" -v w="$w" \
                 -v bs="$4" -v bt="$5" -v bw="$6" \
                 -v ws="$W_SIZE" -v wt="$W_TIME" -v ww="$W_SEC" '
             BEGIN {
               # Normalize (Value / Baseline)
               ns = s / bs
               nt = t / bt
               nw = w / bw
               
               # Composite Cost Function
               ctotal = (ws * ns) + (wt * nt) + (ww * nw)
               
               printf "%.4f %.4f %.4f %.4f", ctotal, ns, nt, nw
             }'
          }

          # Calculate Human & DockAI Scores (explicitly capture output, tolerate failures)
          if output=$(calc_metrics "$h_size" "$h_time" "$h_omega" "$c_size" "$c_time" "$c_omega" 2>/dev/null); then
            set -- $output
            h_score=${1:-0}; h_ns=${2:-0}; h_nt=${3:-0}; h_nw=${4:-0}
          else
            h_score=0; h_ns=0; h_nt=0; h_nw=0
          fi

          if output=$(calc_metrics "$d_size" "$d_time" "$d_omega" "$c_size" "$c_time" "$c_omega" 2>/dev/null); then
            set -- $output
            d_score=${1:-0}; d_ns=${2:-0}; d_nt=${3:-0}; d_nw=${4:-0}
          else
            d_score=0; d_ns=0; d_nt=0; d_nw=0
          fi

          c_score="1.0000"

          # 4. HADOLINT PENALTIES AND FINAL COST
          h_penalty=$(calc_penalty "$h_err" "$h_warn")
          d_penalty=$(calc_penalty "$d_err" "$d_warn")
          c_penalty=$(calc_penalty "$c_err" "$c_warn")

          h_final=$(calc_final "$h_score" "$h_penalty")
          d_final=$(calc_final "$d_score" "$d_penalty")
          c_final=$(calc_final "$c_score" "$c_penalty")

          # Disqualify builds that did not finish
          dq_score="9999"
          if [ "$h_status" != "success" ]; then h_final=$dq_score; h_score=$dq_score; fi
          if [ "$d_status" != "success" ]; then d_final=$dq_score; d_score=$dq_score; fi
          if [ "$c_status" != "success" ]; then c_final=$dq_score; c_score=$dq_score; fi

          # Safe float comparison that tolerates bc parse failures
          safe_lt() {
            local a="${1:-}"
            local b="${2:-}"
            local cmp
            cmp=$(echo "$a < $b" | bc -l 2>/dev/null || echo 0)
            [ "$cmp" -gt 0 ]
          }

          # 5. DETERMINE WINNER (uses final score including penalty)
          winner="No successful builds"
          lowest=""

          if [ "$c_status" = "success" ]; then
            winner="CNB (Baseline)"; lowest=$c_final
          fi

          if [ "$h_status" = "success" ] && { [ -z "$lowest" ] || safe_lt "$h_final" "$lowest"; }; then
            lowest=$h_final; winner="Human"
          fi

          if [ "$d_status" = "success" ] && { [ -z "$lowest" ] || safe_lt "$d_final" "$lowest"; }; then
            lowest=$d_final; winner="DockAI"
          fi

          # Export
          echo "winner=$winner" >> "$GITHUB_ENV"

          # Debug output
          echo "Scores (base) -> CNB: $c_score, Human: $h_score, DockAI: $d_score"
          echo "Penalties -> CNB: $c_penalty, Human: $h_penalty, DockAI: $d_penalty"
          echo "Final -> CNB: $c_final, Human: $h_final, DockAI: $d_final"

          # Generate JSON
          cat <<EOF > results.json
          {
            "baseline": {"status": "$c_status", "size": $c_size, "time": $c_time, "omega": $c_omega, "errors": $c_err, "warnings": $c_warn, "penalty": $c_penalty, "cost": $c_final},
            "human": {"status": "$h_status", "size": $h_size, "time": $h_time, "omega": $h_omega, "errors": $h_err, "warnings": $h_warn, "penalty": $h_penalty, "cost": $h_final},
            "dockai": {"status": "$d_status", "size": $d_size, "time": $d_time, "omega": $d_omega, "errors": $d_err, "warnings": $d_warn, "penalty": $d_penalty, "cost": $d_final},
            "notes": {"disqualified_score": $dq_score, "winner": "$winner"}
          }
          EOF

      - name: Publish GitHub Summary
        if: always()
        run: |
          winner=${winner:-$(jq -r '.notes.winner // "Unknown"' results.json)}
          cat >> "$GITHUB_STEP_SUMMARY" <<EOF
          ## Build-off Summary
          | Method | Status | Cost (C_final) |
          | :--- | :--- | :--- |
          | CNB (Baseline) | $(jq -r '.baseline.status' results.json) | $(jq -r '.baseline.cost' results.json) |
          | Human | $(jq -r '.human.status' results.json) | $(jq -r '.human.cost' results.json) |
          | DockAI | $(jq -r '.dockai.status' results.json) | $(jq -r '.dockai.cost' results.json) |

          **Winner:** ${winner}
          EOF

      - name: Generate Academic Report
        if: always()
        run: |
          # Convert sizes to MB for display
          to_mb() { awk -v v="$1" 'BEGIN {printf "%.2f", v/1024/1024}'; }

          # Read JSON
          hs=$(jq '.human.size' results.json); ht=$(jq '.human.time' results.json); ho=$(jq '.human.omega' results.json); hc=$(jq '.human.cost' results.json); hs_status=$(jq -r '.human.status' results.json)
          ds=$(jq '.dockai.size' results.json); dt=$(jq '.dockai.time' results.json); do=$(jq '.dockai.omega' results.json); dc=$(jq '.dockai.cost' results.json); ds_status=$(jq -r '.dockai.status' results.json)
          cs=$(jq '.baseline.size' results.json); ct=$(jq '.baseline.time' results.json); co=$(jq '.baseline.omega' results.json); bc=$(jq '.baseline.cost' results.json); cs_status=$(jq -r '.baseline.status' results.json)

          cat > "${REPORT_PATH}" <<EOF
          # Empirical Evaluation Report
          **Method:** Composite Optimization Metric (\$C_{total}\$) with Hadolint Penalty (\$C_{final}\$)
          **Winner:** ${winner}

          ## 1. Executive Summary (Lower \$C_{final}\$ is Better)
          | Method | Size (MB) | Build Time (s) | Sec. Index (\$\\Omega\$) | **\$C_{final}\$ Score** |
          | :--- | :--- | :--- | :--- | :--- |
          | **CNB (Baseline)** | $(to_mb $cs) | $ct | $co | **$bc** (Status: $cs_status) |
          | **Human** | $(to_mb $hs) | $ht | $ho | **$hc** (Status: $hs_status) |
          | **DockAI (Ours)** | $(to_mb $ds) | $dt | $do | **$dc** (Status: $ds_status) |

          ## 2. Mathematical Definition
          The **Composite Optimization Metric (\$C_{total}\$)** is calculated as:
          \$\$C_{total} = 0.3 \cdot \hat{S} + 0.2 \cdot \hat{T} + 0.5 \cdot \hat{V}\$\$

          The **Static Analysis Penalty** from Hadolint is:
          \$\$Penalty = 0.1 \cdot Errors + 0.05 \cdot Warnings\$\$

          The final score adds this penalty:
          \$\$C_{final} = C_{total} + Penalty\$\$

          Where:
          * \$\hat{S}, \hat{T}, \hat{V}\$ are normalized ratios against the CNB baseline.
          * Security Index (\$\Omega\$) = \$(10 \times Crit) + (5 \times High) + (2 \times Med) + (1 \times Low)\$
          * Hadolint Errors/Warnings are counted from the JSON lint reports.

          ## 3. Raw Data (For Paper)
          \`\`\`json
          $(cat results.json)
          \`\`\`
          EOF

      - name: Upload Research Data
        if: always()
        uses: actions/upload-artifact@v5.0.0
        with:
          name: research-data
          path: |
            report.md
            results.json
            trivy-*.json
            hadolint-*.json
            *_time.txt
            *_status.txt
